import os
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI

app = FastAPI()

# 2. CORS - Î ÎŸÎ›Î¥ Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ Î“Î™Î‘ Î¤ÎŸ GITHUB PAGES
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 3. Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Ï„Î¿Ï… Hugging Face Client
hf_client = OpenAI(
    base_url="https://router.huggingface.co/v1",
    api_key=os.getenv("HF_TOKEN")
)

chat_history = []

class ChatRequest(BaseModel):
    text: str

# Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÎµÎ½ÏŒÏ‚ GET endpoint Î³Î¹Î± Î½Î± Î¾Î­ÏÎ¿Ï…Î¼Îµ Î±Î½ ÎµÎ¯Î½Î±Î¹ "Î¶Ï‰Î½Ï„Î±Î½ÏŒ"
@app.get("/")
def read_root():
    return {"status": "API is running"}

@app.post("/api/chat")
async def chat_endpoint(data: ChatRequest):
    global chat_history
    
    token = os.getenv("HF_TOKEN")
    if not token:
        return {"reply": "ğŸš¨ Î£Ï†Î¬Î»Î¼Î±: Î¤Î¿ HF_TOKEN Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ Î¿ÏÎ¹ÏƒÏ„ÎµÎ¯ ÏƒÏ„Î± Secrets Ï„Î¿Ï… Space!"}

    try:
        chat_history.append({"role": "user", "content": data.text})

        completion = hf_client.chat.completions.create(
            model="moonshotai/Kimi-K2-Instruct-0905",
            messages=chat_history,
            max_tokens=500
        )

        bot_response = completion.choices[0].message.content
        chat_history.append({"role": "assistant", "content": bot_response})

        return {"reply": bot_response}

    except Exception as e:
        chat_history = [] 
        return {"reply": f"Î£Ï†Î¬Î»Î¼Î± API: {str(e)}"}

@app.post("/api/clear")
async def clear_chat():
    global chat_history
    chat_history = []
    return {"status": "Memory cleared"}